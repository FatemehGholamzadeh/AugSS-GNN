{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2tRnJ7WNnnLz",
        "GbmS4oMvn28Z",
        "xpm4gMkaoGaE",
        "QXzYKtZboSBm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPtr4F8rmPyQ"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#functions for saving and loading pickle files\n",
        "def dump_pickle_file(filename,file):\n",
        "  with open(\"/content/drive/MyDrive/thesis/data/\"+filename+\".pkl\", \"wb\") as tf:\n",
        "    pickle.dump(file,tf)\n",
        "\n",
        "def load_pickle_file(filename):\n",
        "  file_to_read = open(\"/content/drive/MyDrive/thesis/data/\"+filename+\".pkl\", \"rb\")\n",
        "  return pickle.load(file_to_read)"
      ],
      "metadata": {
        "id": "2rm8NwjHmSbz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import AttributedGraphDataset\n",
        "import torch_geometric.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "name_data = 'BlogCatalog'\n",
        "dataset = AttributedGraphDataset(root= '/tmp/' + name_data, name = name_data)\n",
        "\n",
        "# dataset.transform = T.NormalizeFeatures()\n",
        "print(f\"Number of Classes in {name_data}:\", dataset.num_classes)\n",
        "print(f\"Number of Node Features in {name_data}:\", dataset.num_node_features)\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "IYF_nwTTmVHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build content graph**"
      ],
      "metadata": {
        "id": "PeUkEnKHmYvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_sim(A,B):\n",
        "  cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
        "  return cosine\n",
        "\n",
        "features = torch.detach(data.x).numpy()"
      ],
      "metadata": {
        "id": "qO3lG01fmct6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_graph():\n",
        "  sims= np.zeros((len(features),len(features)))\n",
        "  for i,feature in enumerate(features):\n",
        "    for j,feature2 in enumerate(features):\n",
        "      if j<i:\n",
        "        sims[i,j] = cosine_sim(feature,feature2)\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "jeUksyemmgCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_graph():\n",
        "  for i in range(len(features)):\n",
        "    for j in range(len(features)):\n",
        "      if j>i:\n",
        "        sims[i,j]=sims[j,i]"
      ],
      "metadata": {
        "id": "xoltUP-5mhQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dump_pickle_file(\"cosine_similarity_BlogCatalog\",sims)\n",
        "sims= load_pickle_file(\"cosine_similarity_BlogCatalog\")\n",
        "\n",
        "edge_list2 = []\n",
        "for i in range(sims.shape[0]):\n",
        "  for j in range(sims.shape[1]):\n",
        "    if i != j:\n",
        "      if(sims[i][j])>0.2:\n",
        "        edge_list2.append([i,j])"
      ],
      "metadata": {
        "id": "U7y_OXERmiyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.detach(data.y).numpy()\n",
        "keys= [x for x in range(len(y))]\n",
        "y_dictionary = dict(zip(keys, y))\n",
        "score_list= set(y)\n",
        "dic_list= [[] for i in range(len(score_list))]\n",
        "\n",
        "for item in y_dictionary:\n",
        "  dic_list[y_dictionary[item]].append(item)"
      ],
      "metadata": {
        "id": "8tmiY_0lm6_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "l=[]\n",
        "for sample_list in (dic_list):\n",
        "  s_list = random.sample(sample_list, 20)\n",
        "  l.extend(s_list)\n",
        "\n",
        "train_mask = [False for i in range(len(data.x))]\n",
        "for num in l:\n",
        "  train_mask[num] = True\n",
        "mylist = [x for x in range(len(data.x))]\n",
        "mylist = [elt for elt in mylist if elt not in l]\n",
        "l1 = random.sample(mylist, 500)\n",
        "mylist = [elt for elt in mylist if elt not in l1]\n",
        "val_mask = [False for i in range(len(data.x))]\n",
        "for num in l1:\n",
        "  val_mask[num] = True\n",
        "\n",
        "l2 = random.sample(mylist, 1000)\n",
        "test_mask = [False for i in range(len(data.x))]\n",
        "for num in l2:\n",
        "  test_mask[num] = True\n",
        "\n",
        "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
        "data.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
        "data.val_mask = torch.tensor(val_mask, dtype=torch.bool)"
      ],
      "metadata": {
        "id": "nC0hTglsm8ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GCN**"
      ],
      "metadata": {
        "id": "JvYj6KADnGVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval\n",
        "\n",
        "import argparse\n",
        "import os.path as osp\n",
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.logging import init_wandb, log\n",
        "from torch_geometric.nn import GATv2Conv, GCNConv,GATConv\n",
        "from torch.nn import Linear, Parameter\n",
        "from torcheval.metrics.functional import multiclass_f1_score"
      ],
      "metadata": {
        "id": "1-RM2B8jnH1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YQcZWdZMnLqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=200\n",
        "hidden_channels= 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "    F1_score = multiclass_f1_score(pred[data.test_mask],  data.y[data.test_mask], num_classes=dataset.num_classes,average=\"macro\")\n",
        "    accs.append(F1_score)\n",
        "    return accs\n",
        "\n",
        "\n",
        "accuracies=[]\n",
        "F1_scores=[]\n",
        "for k in range(10):\n",
        "\n",
        "  best_val_acc = final_test_acc = 0\n",
        "  model = GCN(dataset.num_features, hidden_channels, dataset.num_classes)\n",
        "  model, data = model.to(device), data.to(device)\n",
        "  optimizer = torch.optim.Adam([\n",
        "      dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
        "      dict(params=model.conv2.parameters(), weight_decay=5e-4)\n",
        "  ], lr=0.01)\n",
        "\n",
        "\n",
        "  for layer in model.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      loss = train()\n",
        "      train_acc, val_acc, tmp_test_acc,tmp_F1_score = test()\n",
        "      if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          test_acc = tmp_test_acc\n",
        "          F1_score = tmp_F1_score\n",
        "      log(Epoch=epoch, k=k,Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc,F1_Score= F1_score)\n",
        "  accuracies.append(test_acc)\n",
        "  print(test_acc)\n",
        "  print(F1_score)\n",
        "  F1_scores.append(F1_score)\n",
        "  print(\"*\"*40)"
      ],
      "metadata": {
        "id": "Ycpt0vIxnOPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AugSS-GCN**"
      ],
      "metadata": {
        "id": "_zq65H0VnSEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.lin= Linear(hidden_channels*2,hidden_channels,bias=False)\n",
        "        self.w1 = torch.nn.Parameter(torch.ones(1).to(device), requires_grad=True)\n",
        "        self.w2 = torch.nn.Parameter(torch.ones(1).to(device), requires_grad=True)\n",
        "\n",
        "    def forward(self, x, edge_index,edge_index2):\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        h1 = self.conv1(x, edge_index).relu()\n",
        "        h2 = self.conv1(x, edge_index2).relu()\n",
        "        # h3= torch.cat((h1,h2),1)\n",
        "        # x3= self.lin(h3)\n",
        "        # x3 = (h1+h2)\n",
        "        x3 = torch.mul(self.w1,h1) +  torch.mul(self.w2,h2)\n",
        "        x3 = F.dropout(x3, p=0.5, training=self.training)\n",
        "        x = self.conv2(x3, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rzRBhWnUnS4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=200\n",
        "hidden_channels= 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "edge_index2 = torch.tensor(edge_list2, dtype=torch.long)\n",
        "edge_index2=edge_index2.t().contiguous()\n",
        "edge_index2= edge_index2.to(device)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index,edge_index2)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index,edge_index2).argmax(dim=-1)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "    F1_score = multiclass_f1_score(pred[data.test_mask],  data.y[data.test_mask], num_classes=dataset.num_classes,average=\"macro\")\n",
        "    accs.append(F1_score)\n",
        "    return accs\n",
        "\n",
        "accuracies=[]\n",
        "F1_scores=[]\n",
        "\n",
        "for k in range(10):\n",
        "\n",
        "  best_val_acc = final_test_acc = 0\n",
        "  model = GCN(dataset.num_features, hidden_channels, dataset.num_classes)\n",
        "  print(model)\n",
        "  model, data = model.to(device), data.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.002, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "  for layer in model.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      loss = train()\n",
        "      train_acc, val_acc, tmp_test_acc,tmp_F1_score = test()\n",
        "      if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          test_acc = tmp_test_acc\n",
        "          F1_score = tmp_F1_score\n",
        "\n",
        "      log(Epoch=epoch, k=k,Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
        "  print(test_acc)\n",
        "  print(F1_score)\n",
        "  accuracies.append(test_acc)\n",
        "  F1_scores.append(F1_score)\n",
        "  print(\"*\"*40)"
      ],
      "metadata": {
        "id": "UtFF-OmRnUl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GAT**"
      ],
      "metadata": {
        "id": "2tRnJ7WNnnLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GATConv(in_channels, 8, heads=8, dropout=0.6)\n",
        "        self.conv2 = GATConv(8 * 8, out_channels, heads=1, concat=False,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "sJ76MXh6nWAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=200\n",
        "hidden_channels= 8\n",
        "heads= 8\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "    F1_score = multiclass_f1_score(pred[data.test_mask],  data.y[data.test_mask], num_classes=dataset.num_classes,average=\"macro\")\n",
        "    accs.append(F1_score)\n",
        "    return accs\n",
        "\n",
        "\n",
        "accuracies=[]\n",
        "F1_scores=[]\n",
        "\n",
        "for k in range(10):\n",
        "\n",
        "  best_val_acc = final_test_acc = 0\n",
        "  model = Net(dataset.num_features, dataset.num_classes)\n",
        "  model, data = model.to(device), data.to(device)\n",
        "  optimizer = torch.optim.Adam([\n",
        "      dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
        "      dict(params=model.conv2.parameters(), weight_decay=5e-4)\n",
        "  ], lr=0.004)\n",
        "\n",
        "\n",
        "  for layer in model.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      loss = train()\n",
        "      train_acc, val_acc, tmp_test_acc,tmp_F1_score = test()\n",
        "      if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          test_acc = tmp_test_acc\n",
        "          F1_score = tmp_F1_score\n",
        "\n",
        "      log(Epoch=epoch, k=k,Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
        "  print(test_acc)\n",
        "  print(F1_score)\n",
        "  accuracies.append(test_acc)\n",
        "  F1_scores.append(F1_score)\n",
        "  print(\"*\"*40)"
      ],
      "metadata": {
        "id": "lHrIvP2Anwdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AugSS-GAT**"
      ],
      "metadata": {
        "id": "GbmS4oMvn28Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1,concat=True, dropout=0.6)\n",
        "        self.w1 = torch.nn.Parameter(torch.Tensor([0.8]).to(device), requires_grad=True)\n",
        "        self.w2 = torch.nn.Parameter(torch.Tensor([0.8]).to(device), requires_grad=True)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_index2):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        h1 = F.elu(self.conv1(x, edge_index))\n",
        "        h2= F.elu(self.conv1(x, edge_index2))\n",
        "        # x3 = torch.mul(self.w1,h1) +  torch.mul(self.w2,h2)\n",
        "        x3= (h1+h2)\n",
        "\n",
        "        x = F.dropout(x3, p=0.6, training=self.training)\n",
        "        x4 = self.conv2(x3, edge_index)\n",
        "        return x4"
      ],
      "metadata": {
        "id": "7kVK4F0gnzy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_channels= 8\n",
        "heads= 8\n",
        "epochs=200\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = data.to(device)\n",
        "\n",
        "edge_index2 = torch.tensor(edge_list2, dtype=torch.long)\n",
        "edge_index2=edge_index2.t().contiguous()\n",
        "edge_index2= edge_index2.to(device)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index,edge_index2)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index,edge_index2).argmax(dim=-1)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "    F1_score = multiclass_f1_score(pred[data.test_mask],  data.y[data.test_mask], num_classes=dataset.num_classes,average=\"macro\")\n",
        "    accs.append(F1_score)\n",
        "    return accs\n",
        "\n",
        "accuracies=[]\n",
        "F1_scores=[]\n",
        "\n",
        "for k in range(10):\n",
        "  best_val_acc = final_test_acc = 0\n",
        "  model = GAT(dataset.num_features, hidden_channels, dataset.num_classes,heads).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.007, weight_decay=5e-4)\n",
        "\n",
        "  for layer in model.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      loss = train()\n",
        "      train_acc, val_acc, tmp_test_acc,tmp_F1_score = test()\n",
        "      if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          test_acc = tmp_test_acc\n",
        "          F1_score = tmp_F1_score\n",
        "\n",
        "      log(Epoch=epoch, k=k,Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
        "  print(test_acc)\n",
        "  print(F1_score)\n",
        "  accuracies.append(test_acc)\n",
        "  F1_scores.append(F1_score)\n",
        "  print(\"*\"*40)"
      ],
      "metadata": {
        "id": "ts57zOdNoBml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GATv2**"
      ],
      "metadata": {
        "id": "xpm4gMkaoGaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels,hidden_channels, out_channels,heads):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads, dropout=0.6)\n",
        "        self.conv2 = GATv2Conv(hidden_channels * heads, out_channels, heads=1, concat=False,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "0HBMnvkqoHur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=200\n",
        "hidden_channels= 20\n",
        "heads= 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=-1)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "    F1_score = multiclass_f1_score(pred[data.test_mask],  data.y[data.test_mask], num_classes=dataset.num_classes,average=\"macro\")\n",
        "    accs.append(F1_score)\n",
        "    return accs\n",
        "\n",
        "accuracies=[]\n",
        "F1_scores=[]\n",
        "\n",
        "for k in range(10):\n",
        "\n",
        "  best_val_acc = final_test_acc = 0\n",
        "  model = Net(dataset.num_features,hidden_channels, dataset.num_classes,heads)\n",
        "  model, data = model.to(device), data.to(device)\n",
        "  print(model)\n",
        "  optimizer = torch.optim.Adam([\n",
        "      dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
        "      dict(params=model.conv2.parameters(), weight_decay=5e-4)\n",
        "  ], lr=0.002)\n",
        "\n",
        "\n",
        "  for layer in model.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      loss = train()\n",
        "      train_acc, val_acc, tmp_test_acc,tmp_F1_score = test()\n",
        "      if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          test_acc = tmp_test_acc\n",
        "          F1_score = tmp_F1_score\n",
        "\n",
        "      log(Epoch=epoch, k=k,Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
        "  print(test_acc)\n",
        "  print(F1_score)\n",
        "  accuracies.append(test_acc)\n",
        "  F1_scores.append(F1_score)\n",
        "  print(\"*\"*40)"
      ],
      "metadata": {
        "id": "tPUZ0ueOoDVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AugSS-GATv2**"
      ],
      "metadata": {
        "id": "QXzYKtZboSBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads, dropout=0.6)\n",
        "        self.conv2 = GATv2Conv(hidden_channels * heads, out_channels, heads=1,\n",
        "                             concat=True, dropout=0.6)\n",
        "        self.w1 = torch.nn.Parameter(torch.Tensor([0.8]).to(device), requires_grad=True)\n",
        "        self.w2 = torch.nn.Parameter(torch.Tensor([0.8]).to(device), requires_grad=True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, edge_index2):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        h1 = F.elu(self.conv1(x, edge_index))\n",
        "        h2= F.elu(self.conv1(x, edge_index2))\n",
        "        # x3= (h1+h2)\n",
        "        x3 = torch.mul(self.w1,h1) +  torch.mul(self.w2,h2)\n",
        "        x = F.dropout(x3, p=0.6, training=self.training)\n",
        "        x4 = self.conv2(x3, edge_index)\n",
        "        return x4"
      ],
      "metadata": {
        "id": "-vdvKc0WoVL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_channels= 8\n",
        "heads= 8\n",
        "epochs=200\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = data.to(device)\n",
        "\n",
        "edge_index2 = torch.tensor(edge_list2, dtype=torch.long)\n",
        "edge_index2=edge_index2.t().contiguous()\n",
        "edge_index2= edge_index2.to(device)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index,edge_index2)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index,edge_index2)\n",
        "    pred = out.argmax(dim=-1)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "    F1_score = multiclass_f1_score(pred[data.test_mask],  data.y[data.test_mask], num_classes=dataset.num_classes,average=\"macro\")\n",
        "    accs.append(F1_score)\n",
        "    return accs\n",
        "\n",
        "accuracies=[]\n",
        "F1_scores=[]\n",
        "\n",
        "for k in range(10):\n",
        "  best_val_acc = final_test_acc = 0\n",
        "  model = GAT(dataset.num_features, hidden_channels, dataset.num_classes,heads).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.007, weight_decay=5e-4)\n",
        "\n",
        "  for layer in model.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      loss = train()\n",
        "      train_acc, val_acc, tmp_test_acc,tmp_F1_score = test()\n",
        "      if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          test_acc = tmp_test_acc\n",
        "          F1_score = tmp_F1_score\n",
        "\n",
        "      log(Epoch=epoch, k=k,Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
        "  print(test_acc)\n",
        "  print(F1_score)\n",
        "  accuracies.append(test_acc)\n",
        "  F1_scores.append(F1_score)\n",
        "  print(\"*\"*40)"
      ],
      "metadata": {
        "id": "rlDEJm4Aoey9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}